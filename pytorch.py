# -*- coding: utf-8 -*-
"""pytorch fundamentals.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13uRbLTugvR_KIAKuwDue317rIH6Zqfl_
"""
from time import time
from pandas._typing import ListLike
import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Scalar
scalar = torch.tensor(7)
scalar

scalar.ndim

# Get the Python number within a tensor (only works with one-element tensors)
scalar.item()

# Vector
vector = torch.tensor([7, 7])
vector

# Check the number of dimensions of vector
vector.ndim

# Check shape of vector
vector.shape

# Matrix
MATRIX = torch.tensor([[7, 8],
                       [9, 10]])
MATRIX

MATRIX.shape

# Check number of dimensions
MATRIX.ndim

import torch
# Tensor
TENSOR = torch.tensor([[[1, 2, 3],
                        [3, 6, 9],
                        [2, 4, 5]]])
TENSOR

# Check number of dimensions for TENSOR
TENSOR.ndim

# Check shape of TENSOR
TENSOR.shape

newTen = torch.tensor([[1,2]])
newTen
newTen.ndim
newTen.shape

"""
## Random tensors"""

# Create a random tensor of size (3, 4)
random_tensor = torch.rand(size=(1, 3, 4))
print(random_tensor)
print(random_tensor, random_tensor.dtype)



# Zeros and Ones
zeros = torch.zeros(size=(3,4))
print(zeros)


ones = torch.ones(size=(3,4))
print(ones)




# Creating a range of tensors and tensors-Like
print(torch.arange(0,10))
print(torch.arange(start=1, end=11, step=2))



# ten_zeros = torch.zeros_like(input=one_to_ten)
# print(ten_zeros)


# Tensor Data types
float_32 = torch.tensor([3.0,6.0,9.0], dtype=None, device="cpu", requires_grad=False)
print(float_32)

float_16 = float_32.type(torch.float16)
print(float_16)

print(float_16 * float_32)

int_32 = torch.tensor([3,6,9], dtype=torch.int32)
print(int_32)
print(float_32 * int_32)



# Getting information from tensors
# datatype = tensor.dtype
# shape = tensor.shape
# device = tensor.device

# Create a tensor
some_tensor = torch.rand([3,4])
print(some_tensor)
print(f"Datatype of tensor: {some_tensor.dtype}")
print(f"Device: {some_tensor.device}")
print(f"Shape of Tensor: {some_tensor.shape}")



# Manipulating tensors
# Addition
tensor = torch.tensor([1,2,3])
print(tensor + 10)
print(tensor)


# Multiplcation
tensor = torch.tensor([4,5,6])
print(tensor * 10)
print(tensor)

# subtraction
tensor = torch.tensor([1,2,3])
print(tensor - 10)
print(tensor)


# division
tensor = torch.tensor([1,2,3])
print(tensor / 10)
print(tensor)

# inbuilt functions
print(torch.add(tensor, 10))
print(torch.mul(tensor, 10))
print(torch.sub(tensor, 10))



# Matrix multiplication
# element wise multiplication
print(torch.mul(tensor, tensor))

# matrix multiplication
print(torch.matmul(tensor, tensor))

# for loop
value = 0
for i in range(len(tensor)):
    value += tensor[i] * tensor[i]
print(value)

# Example 1: (3, 2) @ (2, 3) -> (3, 3)
tensor_A = torch.randn(3, 2)
tensor_B = torch.randn(2, 3)
print(f"Resulting shape: {torch.matmul(tensor_A, tensor_B).shape}")

# Example 2: (10, 5) @ (5, 2) -> (10, 2)
tensor_C = torch.randn(10, 5)
tensor_D = torch.randn(5, 2)
print(f"Resulting shape: {torch.matmul(tensor_C, tensor_D).shape}")

# Shapes for matrix multiplication
tensor_A = torch.tensor([[1,2],
             [3,4],
             [5,6]])
tensor_B = torch.tensor([[7,8],
             [9,10],
             [11,12]])
print(tensor_A.shape)
print(tensor_B.shape)
# we cannot multiply because of shape mismatch
# so we need to tranpose tensor_B
# print(torch.matmul(tensor_A, tensor_B))



# Transpose
tensor_B.T
print(tensor_B.T.shape)
print(tensor_B.T)
print(torch.matmul(tensor_A, tensor_B.T))

# The matrix multiplication works when B is transposed
# their shapes are (3,2) and (2,3) respectively
# and the resulting shape is (3,3)
print(f"Shape of tensor_A: {tensor_A.shape}")
print(f"Shape of tensor_B: {tensor_B.shape}")
print(f"Shape of tensor_B.T: {tensor_B.T.shape}")
print(f"Shape of resulting tensor: {torch.matmul(tensor_A, tensor_B.T).shape}")




# Tensor Aggregation
